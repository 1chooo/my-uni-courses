---
type: slide
title: 06/20 Report        # ç°¡å ±çš„åç¨±
tags: GS4524   # ç°¡å ±çš„æ¨™ç±¤
slideOptions:        # ç°¡å ±ç›¸é—œçš„è¨­å®š
  theme: solarized   # é¡è‰²ä¸»é¡Œ
  slideNumber: true
  transition: 'fade' # æ›é å‹•ç•«
keyboard: true
---


# 06/20 Briefing ðŸ“
### Sleep Analysis
Third-Year @ Dept. ATM

109601003 æž—ç¾¤è³€

---

## The Thesis Topic ðŸ“–

Deep learning for automated sleep staging using instantaneous heart rate

---

## Exploring The Algorithm metioned in this thesis
### With Deep Learning Method
- Current: CNN
- Future: RNN

---

## The Current Method: CNN ðŸŒª

- Not engineer any features
- Only Convolutional layers

---

## First Part about CNN ðŸŒª

- 2 $Hz$ Time Series 72000 -> 1200 segments(30 sec slice)
- 1-D convolutional layers
- 1-d Convolution kernel=7 with dilation = 2, 4, 8, 16, 32
- `Droptout(rate=0.2)`
- `Leaky ReLU (Î±=0.15)`
- (1, 1200, 4) -> (1, 1200, 128)


---

## Second Part about CNN ðŸŒª

- Kernel size still on 1
- Atrous or dilated convolutional blocks
- 1-d Convolution kernel=7 with dilation = 2, 4, 8, 16, 32
- two such dilated convolutional blocks without any pooling layers
- 1200 x 4


---

## The Future Method: RNN

Recurrent Structure -> **Memory**

---

## What I have learned yesterday?

- We can also use 1-D convolutional layer!
- the importance of Dealing with time series data is recalling -> **how to keep to memory**

---

## What I want to Solve today?

- Explore how to Build Convolutional layer with 1-D layer.
- Explore the potential of RNN.

---

# Reference

- [Deep learning for automated sleep staging using instantaneous heart rate](https://www.nature.com/articles/s41746-020-0291-x)

